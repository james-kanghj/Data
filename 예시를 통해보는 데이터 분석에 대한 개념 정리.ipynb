{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---   \n",
    "\n",
    "# Part 1. Mini Project\n",
    "\n",
    "### 비즈니스 문제를 해결하기 위해 데이터로 어떻게 접근, 해결할지 생각해보는 문제\n",
    "    - Q. 1~3 문제 : 잔존율 증가를 위한 비즈니스 문제해결 \n",
    "    - Q. 4~6 문제 : 금융권 VIP 고객의 연간 소비금액을 예측하기 위한 모델 구축 작업\n",
    "    - Q. 7~8 문제 : 유저 세분화 및 그룹핑을 위한 데이터 분석 작업\n",
    "\n",
    "\n",
    "### 머신러닝의 학습과정 및 활용에 대한 이해를 확인하는 문제\n",
    "    - Q. 9 문제 : 손실함수의 필요성과 개념에 대한 이해\n",
    "    - Q. 10~11 문제 : Gradient Descent의 과정과 SGD, MGD 처리 방식의 이해\n",
    "    - Q. 12-13 문제 : 오버피팅 개념 및 해결방법에 대한 이해\n",
    "    - Q. 14-15 문제 : CNN 및 RNN 의 동작원리에 대한 이해와 활용\n",
    "\n",
    "\n",
    "- 작성자: 송훈화 감수자\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q. 1~3. 잔존율 증가를 위한 비즈니스 문제해결 방안 마련\n",
    "\n",
    "### 배경\n",
    "다음과 같은 비즈니스 문제가 있다고 하자. \n",
    "현재 앱서비스의 잔존율이 정체되어 있는 상황이며 재이용자의 증가가 필수적인 상황이다. 여기서 잔존율이란 서비스를 이용하던 기존 유저가 시간이 흘러도 지속적으로 이용하고 있는 정도를 의미한다. \n",
    "\n",
    "\n",
    "### 목표\n",
    "분석가에게 주어진 역할은 사내에 수집된 데이터를 추출해 잔존율을 높일 수 있는 방안을 유관팀에 공유하는 것이다. 유관팀은 개별 유저별로 잔존 여부를 예측할 수 있다면, 이를 근거로 개인화된 타깃팅을 진행할 수 있을 것이다. 분석가는 데이터를 근거로 유저들의 잔존 여부를 예측할 수 있는 모델을 구축하고자 한다. 즉 분석 목표는\n",
    "   - 잔존 vs 비잔존 그룹간의 유저 행동 패턴을 이해하고,\n",
    "   - 개별 유저의 잔존 여부(Y/N)를 예측할 수 있는 모델을 만드는 것이다.\n",
    "\n",
    "위에 주어진 목표를 달성하기 위해 어떤 접근방법을 활용해야할지 각 단계별로 기술해보자.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 수집: 어떤 데이터를 수집/추출할 것인가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. 사내 데이터 활용\n",
    "    - 사내 데이터 활용하는 이유는 앱 서비스이기 때문에, 다른 데이터를 사용할 수 없을 것으로 판단.\n",
    "    \n",
    "    \n",
    "2. 수집/추출할 데이터\n",
    "    - 접속 시간: 이용시간을 확인하기 위한 값\n",
    "    - 이용 시간: 얼마나 사용하고 있는지 패턴을 확인하기 위한 값\n",
    "    - 사용 서비스/기능: 앱 내에 다양한 서비스/기능이 있다면, 사용하고 있는 서비스/기능과 사용하고 있지 않는 서비스/기능을 구분하여 확인하기 위한 값\n",
    "    - 접속 횟수: 접속 빈도 수를 알기 위한 값. 재이용 횟수가 증가하고 있는지 패턴 확인 가능.\n",
    "    - 최근 접속일자: 최근에 접속한 사용자라면 어떤 서비스/기능을 사용함으로서 다시 접속했는지, 서비스/기능 종류와 접속 횟수가 비례하는지 대조하면서 패턴확인 가능. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 탐색적 데이터 분석: 유저의 행동패턴 이해를 위해 데이터 탐색을 어떻게 할 것인가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- 수집한 데이터 중에서 연관지을 수 있는 변수와 변수를 묶어 생각해 볼 수 있다.\n",
    "- 사용했던 서비스/기능들은 무엇인지, 그 서비스/기능 중에서 가장 오래 사용한 서비스/기능은 무엇이며, 얼마나 사용했는지 알 수 있으며, 가장 적은 시간 사용한 서비스/기능에 대해서는 개선의 필요가 있다고 간접적으로 추측해볼 수 있다.\n",
    "- 위와 같이 얻은 결과를 활용해서, 그래프를 통해 수치적/시각화하여 행동패턴에 대해서 이해할 수 있을 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 모형 적합: 어떤 예측모형을 이용해 잔존 여부를 예측할 것인가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- 시간으로서 확인이 가능.\n",
    "- 개인으로 본다면, 사용자가 접속을 주로 언제 했는지, 특정 사용자가 어떤 서비스/기능을 사용했었는지 알 수 있을 것.\n",
    "- 집단으로 본다면, 체류 시간은 30분 단위로 사용 수는 얼마나 되는지, 또는 무슨 요일에 가장 적게 사용하고 가장 오래 사용하는지 예측 가능.\n",
    "- 잔존 즉, 사용시간이 최근에 없거나, 적게 사용했다면, 그 사용 서비스/기능은 무엇인지 확인하여 대책 마련을 할 수 있을 것."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q. 4~6. 금융권 VIP 고객의 연간 소비금액을 예측하기 위한 모델 구축 작업\n",
    "\n",
    "### 배경 및 목표\n",
    "금융권의 한 기업에서 VIP 고객들의 연간 소비금액(단위: 원)을 예측하기 위한 모델을 만들고 있다. 영업팀은 이 예측모델을 새로운 고객관리시스템에 도입하고자 준비하고 있다. 분석가의 목표는 기존 VIP 고객들의 소비금액을 기반으로 새로운 VIP 고객의 연간 소비금액(단위: 원)을 예측하는 것이다.\n",
    "\n",
    "### 데이터셋\n",
    "분석가에게 주어진 데이터셋의 컬럼은 아래와 같다. \n",
    "\n",
    "- 고객아이디(숫자형)\n",
    "- 연봉(숫자형)\n",
    "- 주소(문자) \n",
    "- 연간 소비금액 (숫자형, 단위: 원)\n",
    "- 성별(문자)\n",
    "- 계좌 잔고금액(숫자형, 단위: 원)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 입력 데이터(X, features)로 적절한 변수와 타깃 데이터(y, target, label)로 적절한 변수는 각각 무엇일까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "*입력 데이터(X, features)로 적절한 변수: \n",
    "- 고객아이디(숫자형)\n",
    "- 연봉(숫자형)\n",
    "- 주소(문자) \n",
    "- 성별(문자)\n",
    "- 계좌 잔고금액(숫자형, 단위: 원)\n",
    "\n",
    "*타깃 데이터(y, target, label)로 적절한 변수: \n",
    "- 연간 소비금액 (숫자형, 단위: 원)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 지도학습(회귀), 지도학습(분류), 비지도학습, 강화학습 중에 어떤 모델을 적용할 것인가?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. 지도학습(회귀): 타겟 Y가 연속형 변수(연속 범위 내에서 임의의 값을 가질 수 있는 변수)인 경우에만 사용가능.\n",
    "2. 지도학습(분류): 타겟 Y가 이산형 변수(특정한 값만 가질 수 있는 변수)인 경우에만 사용가능.\n",
    "3. 비지도학습: 타겟(Y) 값이 없는 입력(X) 값만을 학습하는 방법.\n",
    "4. 강화학습: 자전거를 배우는 과정과 같이, 자신이 한 행동에 대한 보상을 바탕으로 목적을 달성하는 학습.\n",
    "\n",
    "위 설명에 따라서 결과 즉, 연간 소비금액은 특정한 값이 아니기 때문에, \"지도학습(회귀)\" 모델을 적용하는 것이 적절할 것으로 보입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 생성된 모델이 학습 데이터에서는 성능이 높았으나 테스트 데이터에서 성능이 낮았다. 추정되는 이유는 무엇인가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "아래 2가지 이유로 추정해볼 수 있을 것으로 판단됩니다.\n",
    "- 새로운 고객관리시스템이라는 점에서, 많은 데이터의 준비가 부족했기 때문에.\n",
    "- 더 구체적인 입력 데이터가 필요하기 때문에.\n",
    "\n",
    "즉, 충분한 데이터가 없어서, 충분한 결과를 내기에 충분한 데이터의 양이 아니라는 점으로 추정해 볼 수 있을 것 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7~8.  유저 세분화 및 그룹핑을 위한 데이터 분석 작업\n",
    "\n",
    "### 배경 및 목표\n",
    "전체 소비자를 대상으로 한 마케팅 비용 및 리소스가 매우 큰 것으로 나타남에 따라, 전체 소비자를 세분화하여 그룹을 만든후 특정 그룹을 대상으로 마케팅을 진행하고자 한다. 분석가의 역할은 주어진 아래 데이터셋을 가지고 소비자를 세분화된 결과를 마케팅팀에 공유하는 것이다.\n",
    "\n",
    "### 데이터셋\n",
    "\n",
    "- 유저 아이디(숫자형)\n",
    "- 방문당 평균 결제횟수 (숫자형)\n",
    "- 방문당 공유 횟수 (숫자형)\n",
    "- 재방문율 (숫자형)\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 지도학습(회귀), 지도학습(분류), 비지도학습, 강화학습 중에 어떤 모델을 적용할 것인가? 이유는 무엇인가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. 지도학습(회귀): 타겟 Y가 연속형 변수(연속 범위 내에서 임의의 값을 가질 수 있는 변수)인 경우에만 사용가능.\n",
    "2. 지도학습(분류): 타겟 Y가 이산형 변수(특정한 값만 가질 수 있는 변수)인 경우에만 사용가능.\n",
    "3. 비지도학습: 타겟(Y) 값이 없는 입력(X) 값만을 학습하는 방법.\n",
    "4. 강화학습: 자전거를 배우는 과정과 같이, 자신이 한 행동에 대한 보상을 바탕으로 목적을 달성하는 학습.\n",
    "\n",
    "이 케이스의 경우, 정답이 없는 데이터셋을 학습하는 것이므로 비지도학습을 적용해야 한다. 비지도학습을 위한 모델로는 군집화가 있다.\n",
    "\n",
    "군집화는 레이블이 없는 학습 데이터들의 특징을 분석하여 서로 동일하거나 유사한 특징을 가진 데이터끼리 그룹화 함으로써, 레이블이 없는 학습 데이터를 그룹으로 분류한다. 그리고 새로운 데이터가 입력되면 지도 학습의 분류 모델처럼 학습한 그룹을 가지고 해당 데이터가 어느 그룹에 속하는지 분석하는 것을 말한다.\n",
    "\n",
    "위와 같은 케이스 데이터에는 레이블이 명시되어 있지 않기 때문에 지도 학습과 다른 방법을 수행해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 만약 위 변수를 가지고 명확히 소비자가 세분화되지 않는다면 어떻게 해결하는 것이 좋을까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "연관성을 발견하므로서 서로의 관계를 파악할 수 있다. 규칙을 통한 패턴을 예측할 수 있을 것이다.\n",
    "이 케이스의 예로서, 재방문률에 따라서 방문당 평균 결제횟수 또는 방문당 공유 횟수와 연관성을 알 수 있을 수 있으며, 다른 결과를 위 변수를 통해서 발견할 확률이 존재한다.\n",
    "그렇게 특정 패턴이 존재한다면, 그룹핑을 추가적으로 시킬 수 있을 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 9. 머신러닝에서 손실함수는 모델의 학습과정에서 매우 중요한 역할을 한다. 이 역할에 대해 상세히 기술해보자. 그리고 회귀, 분류 각 문제별로 대표적인 손실함수를 예로 들어보자.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "손실함수는 학습 알고리즘이 작동하도록 만들어주는 원동력의 역할을 한다. 그래서 중요하다.\n",
    "실제 데이터에서 관측된 결과와 모델에 의해 생성된 결과, 이 둘의 차이에 의해 발생되는 것이 손실이다.\n",
    "손실은 마이너스라는 개념이므로, 손실의 값은 적을 수록 모델의 성능은 좋다고 말할 수 있다.\n",
    "\n",
    "즉, 높은 정확도를 끌어내는 것이 목적이고, 정확도라는 지표를 손실함수의 값으로 표현한다.\n",
    "정확도라는 표현을 두고 손실함수라고 표현하는 이유는 미분값이 대부분에서 0이 되어 매개변수를 갱신할 수 없기 때문이다.\n",
    "\n",
    "분류의 예로는 '교차 엔트로피', 회귀의 예로는 '평균 제곱 오차'가 있다.\n",
    "교차 엔트로피 오차는 더 작은 값일수록 정확도가 높다고 판단한다.\n",
    "평균 제곱 오차는 오차가 더 작을수록 정확도가 더 높다고 판단한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10~11. Gradient Descent의 과정과 SGD, MGD 처리 방식의 이해\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Gradient Descent 는 손실함수를 최소화하는 Weight을 찾아내기 위해 점진적으로 진행하는 최적화 방법중 하나이다. 경사하강법을 통해 손실함수 값을 최소화하는 과정을 간단히 기술해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- 손실함수 값을 최소화한다는 것은, 손실함수의 값이 줄어들도록 가중치 값들을 조금씩 조정하는 것이다.\n",
    "- 가중치의 값은 미분을 통해 조정할 수 있다. \n",
    "- 손실함수를 임의의 점에서의 접선의 기울기에 대한 것을 미분하고, 미분값을 가리키는 방향의 \"반대방향\"으로 아주 조금씩 미분값 즉, 접선의 기울기를 줄여감으로서 손실함수의 값을 감소시킬수 있다.\n",
    "- 이는 산 위에서 눈 가리고 내려가는 것과 마찬가지의 원리이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. 많은 데이터에 대해 한번에 Gradient Descent 를 적용했을 때(즉 Batch 처리) 학습에 시간이 오래 걸리는 문제가 발생한다. 따라서 Stochastic, Mini-batch Gradient Descent 과 같은 방법들을 사용하는데, 각 방법들에 대해 기술해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Stochastic Gradient Descent\n",
    "\n",
    ": 데이터를 1개만 뽑고, 그 1개의 데이터에 대한 손실을 이용하여 Gradient Descent\n",
    "\n",
    "\n",
    "- Mini-batch Gradient Descent\n",
    "\n",
    ": Batch/Stochastic의 중간 형태로서, 데이터를 n개 뽑고, 그 n개의 데이터에 대한 손실을 계산하여 다 더한 뒤 이를 이용하여 Gradient Descent.\n",
    "\n",
    "(이 방법을 가장 많이 사용한다.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 12~13. 오버피팅 개념 및 해결방법에 대한 이해\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. 머신러닝 모델을 구축하기 위해 전체 데이터를 학습셋, 검증셋, 테스트셋으로 분리시키는데 이렇게 분리시키는 목적은 무엇이며, 각 데이터셋의 이용 목적을 기술해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "분리시키는 목적: 머신러닝 모델에 학습셋 100% 학습시킨 후 테스트데이터에 모델을 적용했을 때, 성능이 생각보다 나오지 않는 경우가 대부분이다. 이를 오버피팅(overfitting)이라고 하는데, 오버피팅을 방지하는 것 즉, 전체적인 모델 성능을 따져보앗을 때 매우 중요한 프로세스 중 하나이기 때문에 분리한다.\n",
    "\n",
    "각 데이터셋의 이용 목적: \n",
    "- 학습셋: 학습에 사용하는 데이터들의 집합\n",
    "- 검증셋: 학습에는 사용하지 안혹, 하이퍼 파라미터 튜닝에 사용하는 데이터들의 집합\n",
    "- 테스트셋: 학습이 완전하게 끝난 후, 모델을 평가하기 위한 데이터들의 집합. 즉, 알고리즘 성능 평가에 사용하는 데이터들의 집합."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.  과적합(Overftting)이 발생했을 때 이를 해결할 수 있는 방안은 무엇이 있을지 작성해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "오버피팅(overfitting)이 발생했을 때 해결할 수 있는 방법은 아래와 같이 크게 2가지이다.\n",
    "1. 데이터 양을 늘리거나,\n",
    "2. Regularization 방법을 사용한다.\n",
    "\n",
    "데이터 양을 늘리는 것은 말 그대로 데이터의 수를 늘리는 것이며,\n",
    "Regularization 방법은 L1/L2 Regularization, Dropout, Batch normalization과 같은 방법 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 14~15. CNN 및  RNN 의 동작원리에 대한 이해와 활용\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 14. 주로 이미지 인식을 위해 가장 널리 알려진 CNN(Convolutional Neural Network)의 학습과정에 대해 간단히 기술해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "convolution과 pooling을 반복 즉, 이미지를 타일 형태로 나누고, 각각의 타일에서 특정 feature를 추출하여 fully connected layer 즉, 각각의 결과를 다음 레이어로 보내면서 계속 반복합니다. 반복하여 최종적으로 추출된 모든 features를 조합하여 최종적으로 이미지를 판단합니다.\n",
    "각각의 타일의 feature에서 귀, 코, 눈 등으로 판단되는 정보를 하나로 합쳐서 개, 사람, 고양이 등으로 판단을 내리게 되는 학습방법입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. RNN(Recurrent Neural Network)의 개념과 대표적인 문제점, 해결방법에 대해 기술해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- 개념: RNN은 신경망(Neural Network)의 일종으로서, 음성인식, 자연어 등 현재 입력 데이터와 과거 데이터를 고려하여 순차 데이터를 처리하는 순환 신경망 모델이다.\n",
    "- 대표적인 문제점: 시퀀스가 길어지면 성능이 떨어지며, 학습도 잘 안 될 뿐더러, 오래 전에 입력한 것에 대해서는 기억을 잘 못하는 문제점이 있다. 즉, 현재 노드와 먼 과저거 상태를 사용한 문맥 처리가 어렵다.\n",
    "- 해결방법: 오래 전에 입력한 것에 대해서 기억 못하는 장기 의존성 문제를 해결하기 위해, LSTM(Long Short Term Memory), GRU(Gated Recurrent Unit)가 고안되었다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
