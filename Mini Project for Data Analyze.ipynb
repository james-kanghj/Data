{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Project 15 문제\n",
    "\n",
    "- **비즈니스 문제를 해결하기 위해 데이터로 어떻게 접근, 해결할지 생각해보는 문제**\n",
    "    - #1~#3: 잔존율 증가를 위한 비즈니스 문제해결 \n",
    "    - #4~#6: 금융권 VIP 고객의 연간 소비금액을 예측하기 위한 모델 구축 작업\n",
    "    - #7~#8: 유저 세분화 및 그룹핑을 위한 데이터 분석 작업\n",
    "\n",
    "\n",
    "- **머신러닝의 학습과정 및 활용에 대한 이해를 확인하는 문제**\n",
    "    - #9: 손실함수의 필요성과 개념에 대한 이해\n",
    "    - #10~#11: Gradient Descent의 과정과 SGD, MGD 처리 방식의 이해\n",
    "    - #12-#13: 오버피팅 개념 및 해결방법에 대한 이해\n",
    "    - #14-#15: CNN 및 RNN 의 동작원리에 대한 이해와 활용\n",
    "\n",
    "---    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #1~#3. 잔존율 증가를 위한 비즈니스 문제해결 방안 마련\n",
    "\n",
    "### 배경\n",
    "다음과 같은 비즈니스 문제가 있다고 하자.\n",
    "현재 앱서비스의 잔존율이 정체되어 있는 상황이며 재이용자의 증가가 필수적인 상황이다. 여기서 잔존율이란 서비스를 이용하던 기존 유저가 시간이 흘러도 지속적으로 이용하고 있는 정도를 의미한다.\n",
    "\n",
    "\n",
    "### 목표\n",
    "분석가에게 주어진 역할은 사내에 수집된 데이터를 추출해 잔존율을 높일 수 있는 방안을 유관팀에 공유하는 것이다.\n",
    "유관팀은 개별 유저별로 잔존 여부를 예측할 수 있다면, 이를 근거로 개인화된 타깃팅을 진행할 수 있을 것이다.\n",
    "분석가는 데이터를 근거로 유저들의 잔존 여부를 예측할 수 있는 모델을 구축하고자 한다.\n",
    "즉 분석 목표는,\n",
    "   - 잔존 vs 비잔존 그룹 간의 유저 행동 패턴을 이해하고,\n",
    "   - 개별 유저의 잔존 여부(Y/N)를 예측할 수 있는 모델을 만드는 것이다.\n",
    "\n",
    "위에 주어진 목표를 달성하기 위해 어떤 접근방법을 활용해야할지 각 단계별로 기술해보자.\n",
    " \n",
    " \n",
    "### #1. 데이터 수집: 어떤 데이터를 수집/추출할 것인가?\n",
    "> 유저의 신원을 파악할 수 있는 유니크한 Identification 정보가 필요하며, 유저 별 행동을 파악할 수 있는 로그나 히스토리성 데이터가 기본적으로 필요하다. 만약 유저별 행동을 집계한 마트 테이블(예, 지난 1주간 방문 횟수 등)이 있다면 이를 활용할 수 있다.\n",
    "모델 구축을 위해 반드시 필요한 변수는 모델의 타깃값(y)으로 활용할 유저 별 잔존 여부에 대한 데이터이다. 입력 데이터로는 지난 1주 간 방문 횟수나 결제 금액, 연령, 지역 등 다양한 변수가 고려될 수 있다. \n",
    "\n",
    "> 체크리스트\n",
    " - 유니크한 ID 정보에 대한 언급이 있는가?\n",
    " - 유저의 행동을 파악할 수 있는 로그, 히스토리성 데이터의 언급이 있는가?\n",
    " - 잔존 여부(Y/N 혹은 1/0)를 표현하는 컬럼에 대한 언급이 있는가?\n",
    "\n",
    "\n",
    "### #2. 탐색적 데이터 분석: 유저의 행동패턴 이해를 위해 데이터 탐색을 어떻게 할 것인가?\n",
    "\n",
    "> 잔존 여부를 기준으로 그룹 별로 나누는 것이 기본적으로 해야할 일이다. 그 다음에 그룹별 행동패턴의 차이를 자세히 살펴보아야 한다.\n",
    "만약 지난 1주일 간 방문 횟수라는 숫자형 데이터가 있다면, 그룹 별로 방문 횟수의 평균이나 중앙치의 차이가 유의미하게 존재하는지 분포 형태는 어떻게 다른지 등을 파악할 필요가 있다. 만약 성별과 같이 범주형 자료라면, cross table을 통해 그룹 별 빈도나 비중의 차이가 있는지 파악해야 한다.\n",
    "마지막으로 할 일은 모델에 적용할 변수를 선택하는 일이다. 그룹 간의 차이를 유의미하게 구별해주는 변수를 위주로 모델에 적용해야 성능이 좋은 모델이 나올 수 있다.\n",
    "\n",
    "> 체크리스트\n",
    "- 잔존 여부로 그룹을 구분하는 것을 언급하는가?\n",
    "- 행동 패턴의 차이를 파악하기 위해 데이터 형태(숫자형, 범주형)에 맞게 적절한 분석을 진행하는가? (예, 범주형의 경우 cross table, 카이제곱검정 등이 필요하며 숫자형의 경우 히스토그램을 통한 분포 확인, T-test, ANOVA 등이 필요함)\n",
    "- 입력 데이터(X, features, input) 및 타깃 데이터(y, label, output)에 대한 구분을 하는가?\n",
    "\n",
    "\n",
    "### #3. 모형 적합: 어떤 예측모형을 이용해 잔존 여부를 예측할 것인가?\n",
    "\n",
    "> 탐색적 데이터 분석을 통해 유의미한 변수를 선정하고 분류(classificatoin) 모델들을 구축한다. 대표적으로 Logistic Regression, Decision Tree, KNN, Neural Network 모델 등을 적용해 볼 수 있을 것이다. 모델 구축후 성능을 테스트하고 적당한 성능을 보인다면 비즈니스 문제 해결에 활용한다.\n",
    "\n",
    "> 체크리스트\n",
    "- Classfication 모델중 하나 이상을 언급하는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #4~#6. 금융권 VIP 고객의 연간 소비금액을 예측하기 위한 모델 구축 작업\n",
    "\n",
    "### 배경 및 목표\n",
    "금융권의 한 기업에서 VIP 고객들의 연간 소비금액(단위: 원)을 예측하기 위한 모델을 만들고 있다.\n",
    "영업팀은 이 예측 모델을 새로운 고객 관리 시스템에 도입하고자 준비하고 있다.\n",
    "분석가의 목표는 기존 VIP 고객들의 소비 금액을 기반으로 새로운 VIP 고객의 연간 소비금액(단위: 원)을 예측하는 것이다.\n",
    "\n",
    "### 데이터셋\n",
    "분석가에게 주어진 데이터셋의 컬럼은 아래와 같다. \n",
    "- 고객아이디(숫자형)\n",
    "- 연봉(숫자형)\n",
    "- 주소(문자)\n",
    "- 연간 소비금액 (숫자형, 단위: 원)\n",
    "- 성별(문자)\n",
    "- 계좌 잔고금액(숫자형, 단위: 원)\n",
    "\n",
    "\n",
    "### #4. 입력 데이터(X, features)로 적절한 변수와 타깃 데이터(y, target, label)로 적절한 변수는 각각 무엇일까?\n",
    "> 타깃 데이터로 연간 소비 금액을 이용해야 하며, 연봉, 주소, 성별, 계좌 잔고 금액을 입력 데이터로 이용할 수 있다. 참고로 고객 아이디는 입력 데이터로 모델에 들어가면 안 된다. 이는 각 행을 구분하는 인덱스의 역할을 할뿐, 입력 데이터로서는 역할을 하지 못하기 때문이다. 따라서 모델 구축 전 데이터 탐색과정까지만 이용하고, 모델학습에 들어가기 전에 제거해야 한다.\n",
    "\n",
    "> 체크리스트\n",
    "- 타깃 데이터와 입력 데이터에 적절한 변수를 잘 선별하는가?\n",
    "- 고객 아이디를 입력 데이터에 포함시키지 않았는가\n",
    "\n",
    "\n",
    "### #5. 지도학습(회귀), 지도학습(분류), 비지도학습, 강화학습 중에 어떤 모델을 적용할 것인가? \n",
    "> 예측하고자 하는 값이 금액(숫자형, 실수)이므로 지도학습(회귀) 모델을 적용해야 한다. Linear Regression이 대표적인 모델이며 Decision Tree, Random Forest, GBT와 같은 Tree 계열, KNN, Neural Network 등을 이용해볼 수 있다.\n",
    "\n",
    "> 체크리스트\n",
    "- 지도학습(회귀)를 적용할 모델로 선택하였는가?\n",
    "\n",
    "\n",
    "### #6. 생성된 모델이 학습 데이터에서는 성능이 높았으나 테스트 데이터에서 성능이 낮았다. 추정되는 이유는 무엇인가?\n",
    "> 전형적인 과적합(Overfitting) 문제이다. 우리가 기대하는 것은 모델이 새로 주어진 데이터(즉 테스트 데이터)에서 높은 성능을 보이는 것이다. 그래야 이 모델이 일반화할 수 있다고 판단하고 비즈니스에서 활용할 수 있다. 만약 학습 데이터에서만 높은 성능을 보인다면, 가중치가 너무 크거나 불필요하게 복잡한 수식으로(예, 다항식) 학습했을 가능성이 있다. 이를 해결하기 위해 정규화(L1, L2)를 적용하거나 변수의 수를 줄이거나 더 단순한 회귀식(일차 함수) 등을 적용할 필요가 있다.\n",
    "\n",
    "> 체크리스트\n",
    "- 과적합, Overfitting을 이슈의 원인으로 언급하고 있으며 개념과 중요성을 이해를 하고 있는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #7~#8.  유저 세분화 및 그룹핑을 위한 데이터 분석 작업\n",
    "\n",
    "### 배경 및 목표\n",
    "전체 소비자를 대상으로 한 마케팅 비용 및 리소스가 매우 큰 것으로 나타남에 따라, 전체 소비자를 세분화하여 그룹을 만든후 특정 그룹을 대상으로 마케팅을 진행하고자 한다. 분석가의 역할은 주어진 아래 데이터셋을 가지고 소비자를 세분화된 결과를 마케팅팀에 공유하는 것이다.\n",
    "\n",
    "### 데이터셋\n",
    "- 유저 아이디(숫자형)\n",
    "- 방문당 평균 결제횟수 (숫자형)\n",
    "- 방문당 공유 횟수 (숫자형)\n",
    "- 재방문율 (숫자형)\n",
    "\n",
    "\n",
    "### #7. 지도학습(회귀), 지도학습(분류), 비지도학습, 강화학습 중에 어떤 모델을 적용할 것인가? 이유는 무엇인가?\n",
    "> '비지도 학습'을 적용해야 하며, K-means 와 같은 클러스터링 기법을 이용해야 한다. 비지도 학습은 예측하고자 하는 타깃값(y)이 없는 경우를 의미하며, 이번처럼 전체 소비자를 그룹핑하는 경우에 이용할 수 있다. 지도 학습과 달리, 그룹핑의 결과가 좋은지 진단할 수 있는 방법이 없으므로 도메인 전문가의 지식이나 다양한 논의 등을 통해 결과의 좋고 나쁨을 파악해야 한다.\n",
    "\n",
    "> 체크리스트\n",
    "- 비지도학습 혹은 clustering 에 대한 언급을 하였는가?\n",
    "- 비지도학습과 지도학습의 차이를 이해하는가? (타깃변수의 유무)\n",
    "\n",
    "\n",
    "### #8. 만약 위 변수를 가지고 명확히 소비자가 세분화되지 않는다면 어떻게 해결하는 것이 좋을까?\n",
    "> 새로운 변수를 추출하거나 파생 변수를 만들어내는 것이 방안이 될수 있다. 또한 수치형 자료를 표준화(z-score) 점수로 변환하거나 min-max 스케일링하여 수치를 변환해보는 것도 도움이 될 수 있다. 일반적으로, 측정 스케일이 다른 경우가 많으므로 평균을 기준으로 각 개별값이 얼마나 떨어져있는지 계산한 후 표준편차로 나누는 z-score 기법을 통해 표준화한후 clustering을 하는 방법을 많이 이용한다.\n",
    "\n",
    "> 체크리스트\n",
    "- 새로운 변수를 탐색하거나 점수를 표준화하는 등의 문제 해결을 위한 아이디어를 하나 이상 제공하는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #9. 머신러닝에서 손실함수는 모델의 학습과정에서 매우 중요한 역할을 한다. 이 역할에 대해 상세히 기술해보자. 그리고 회귀, 분류 각 문제별로 대표적인 손실함수를 예로 들어보자.\n",
    "> 머신러닝에서 학습과정이란 손실함수을 정의하고 이 값을 최소로 하는 변수별 가중치(Weight)을 찾는 과정을 의미한다. 여기서 주로 손실의 개념은 예측한 결과와 실제 간의 차이를 의미하며, 이를 찾는 방법은 점진적 시도를 통해 최적값을 찾는 Gradient Descent 계열과 방정식으로 해를 찾는 OLS(Ordinary Least Sqaure) 등 다양하게 존재한다. 분류의 경우 Cross-entropy를, 회귀의 경우 RMSE나 MSE 등을 손실함수로 주로 사용한다.\n",
    "\n",
    "> 체크리스트\n",
    "- 손실함수의 역할을 명확히 이해하는가?\n",
    "- 분류, 회귀별로 대표적인 손실함수를 언급하는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #10~#11. Gradient Descent의 과정과 SGD, MGD 처리 방식의 이해\n",
    "\n",
    "### #10. Gradient Descent 는 손실함수를 최소화하는 Weight을 찾아내기 위해 점진적으로 진행하는 최적화 방법중 하나이다. 경사하강법을 통해 손실함수 값을 최소화하는 과정을 간단히 기술해보자.\n",
    "> 손실 함수를 정의했다면 이 함수를 미분한 값을 이용하여 Gradient Descent를 진행한다. 함수의 형태가 볼록한(convex) 상태이어야 하며, 우선 랜덤하게 Weight의 값(X축)을 손실함수에 적용한 뒤, 해당 손실값(y축)을 확인한다. 이 손실값이 최소인, 즉 미분값(기울기)이 0인 Weight을 점진적으로 찾는 것이 Gradient Descent의 목표이다. 만약 기울기가 음수라면 손실값이 최소값이 되기 위해 X축 기준 오른쪽 방향으로 이동해야 하며, 기울기가 양수라면 왼쪽으로 이동해야 최적의 Weight에 도달할 수 있게 된다. Gradient Descent의 식을 보면 계속 Weight를 업데이트하는데, Learning Rate에 손실함수를 미분한 값(기울기) 곱한 값을 기존 Weight에서 빼주는 과정을 반복한다. 따라서 기울기가 음수라면 Weight의 값이 커지는 오른쪽으로, 기울기가 양수라면 값이 작아지는 왼쪽으로 이동하게 되는 원리가 Gradient Descent를 활용한 최적화 방법이다. 여기서 보폭(한번에 얼만큼 이동할지)을 정의하는데 이를 learning rate이라고 하며, 이 값이 너무 작으면 수렴하는데 시간이 오래 걸리고, 너무 크면 최적값에 도달하지 못하고 overshoot하게 된다.\n",
    "\n",
    "> 체크리스트\n",
    "- Gradient Descent의 목적과 전반적인 과정을 이해하고 있는가?\n",
    "\n",
    "### #11. 많은 데이터에 대해 한번에 Gradient Descent 를 적용했을 때(즉 Batch 처리) 학습에 시간이 오래 걸리는 문제가 발생한다. 따라서 Stochastic, Mini-batch Gradient Descent 과 같은 방법들을 사용하는데, 각 방법들에 대해 기술해보자.\n",
    "> Stochastic Gradient Descent는 전체 데이터 중에 한 개의 데이터만 랜덤하게 샘플링하여 Gradient Descent를 진행하는 것이며 학습속도가 빠르지만, 다소 부정확할 수 있고 반복할 때마다 결과 값의 변동성이 큰 편이다. Mini-batch Gradient Descent는 일괄처리(Batch)와 SGD의 중간 형태로 데이터를 n번 샘플링을하여 샘플링된 데이터로 n개의 손실함수 값을 계산하여 평균값을 이용한 방식이다.\n",
    "\n",
    "> 체크리스트\n",
    "- Batch 방식의 단점을 이해하고 있는가?\n",
    "- SGD, MGD의 차이점을 명확히 구분하는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #12~#13. 오버피팅 개념 및 해결방법에 대한 이해\n",
    "\n",
    "### #12. 머신러닝 모델을 구축하기 위해 전체 데이터를 학습셋, 검증셋, 테스트셋으로 분리시키는데 이렇게 분리시키는 목은 무엇이며, 각 데이터셋의 이용 목적을 기술해보자.\n",
    "> 머신러닝(딥러닝) 모델은 이미 정답이 주어진 학습 데이터셋을 제시했을 때만 높은 성능을 보이는 게 아니라, 정답이 없는 즉, 새로운 데이터셋(테스트 데이터셋)이 주어졌을 때도 높은 성능을 유지할 필요가 있다. 이를 일반화가 잘 되었다고 할 수 있는데, 만약 머신러닝 모델이 학습데이터에서 높은 성능을 보였으나 테스트 데이터셋에서는 낮은 성능을 보였다면 이를 '오버피팅'이라고 하며 이를 파악하기 위해 전체 데이터셋을 3개로 분류해서 학습을 진행한다. 학습 데이터셋은 모델을 만드는데 이용하고 검증 데이터셋은 높은 성능을 보이는 하이퍼파라메터를 찾기 위해, 그리고 테스트셋은 오버피팅을 확인하기 위해서 이용한다.\n",
    "\n",
    "> 체크리스트\n",
    "- 오버피팅에 대한 언급을 하고 개념을 이해하는가?\n",
    "- 학습셋, 검증셋, 테스트셋의 각 역할을 이해하는가?\n",
    "\n",
    "\n",
    "### #13.  과적합(Overftting)이 발생했을 때 이를 해결할 수 있는 방안은 무엇이 있을지 작성해보자.\n",
    "> 일반적으로 오버피팅이 발생하는 이유는 학습 데이터에 지나치게 적합이된 모델을 구축했기 때문이다. 따라서 모델이 학습 데이터에 지나치게 적합되지 않도록 데이터의 양을 늘리거나, Feature의 수를 줄이거나, Weight을 줄여주는 정규화를 진행하거나 Batch Normalization 을 고려해볼 수 있다.\n",
    "\n",
    "> 체크리스트\n",
    "- 두 개이상의 오버피팅 이슈 해결책에 대해 언급하는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #14~#15. CNN 및  RNN 의 동작원리에 대한 이해와 활용\n",
    "\n",
    "\n",
    "### #14. 주로 이미지 인식을 위해 가장 널리 알려진 CNN(Convolutional Neural Network)의 학습과정에 대해 간단히 기술해보자.\n",
    "> 이미지를 잘게 나누고 필터가 특정 간격으로 움직이면서 이미지의 특징을 추출해 이미지가 무엇인지 판단하는 과정을 말한다. Convolution layer의 역할은 이미지에서 Feature(특징들)를 추출하는 역할을하며 Pooling layer는 추출된 특징 중 중요한 특징을 뽑는 역할을 한다. 마지막으로 Fully-connect layer는 최종적인 특징을 조합해 이미지가 무엇인지 판단하는 역할을 한다.\n",
    "\n",
    "> 체크리스트\n",
    "- CNN의 학습 과정을 이해하는가?\n",
    "- Convolution layer, Pooling layer, Fully-connect layer의 각 역할에 대해 기술하는가?\n",
    "\n",
    "\n",
    "### #15. RNN(Recurrent Neural Network)의 개념과 대표적인 문제점, 해결방법에 대해 기술해보자.\n",
    "> RNN은 시퀀스(순서가 있는) 데이터를 학습하기 위한 것으로 주로 순서가 정해져있는 데이터를 학습할 때 이용된다. 음성이나 텍스트 등 순서가 있는 데이터 형태에 적합한 것으로 알려져 있으며 기존의 데이터를 업데이트하면서 순환하기 때문에 '순환신경망'이라고도 불리고 있다. 문제는 데이터의 길이가 길면, 즉 지점과 지점 사이의 거리가 멀면 모델의 성능이 떨어진다는 점이며, 이를 해결하기 위한 것이 LSTM, GRU 등이 있다.\n",
    "\n",
    "> 체크리스트\n",
    "- RNN의 개념과 문제점, 해결방법에 대해 언급하는가?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
